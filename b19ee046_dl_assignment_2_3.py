# -*- coding: utf-8 -*-
"""B19EE046_DL_Assignment_2_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s2TkK55tNYsvN2CTYw1UF5ECij_5WdPq
"""

from google.colab import drive
drive.mount('/content/drive')

"""# Importing Necessary Libraries"""

import numpy as np
import torch
from torchvision import datasets, transforms
from tqdm import tqdm
import matplotlib.pyplot as plt
import os
import cv2
from PIL import Image
from random import shuffle
import pandas as pd
from torch.utils.data import Dataset
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
device

"""# Dataset Handling

## Unzipping the Dataset File
"""

!unzip '/content/drive/MyDrive/DL_Assignment_2/kagglecatsanddogs_3367a.zip' -d '/content/drive/MyDrive/DL_Assignment_2/'

"""## Function to Split the Dataset into Train and Test portions alongside creating meta-file (Images and Labels)"""

def train_test_split(directory_origin, directory_new_train, directory_new_test, class_name, test_size=0.1, shuffle_option=False):
  count=0
  if shuffle_option!=True:
    list_images = os.listdir(directory_origin)
  else:
    list_images = os.listdir(directory_origin)
    shuffle(list_images)
  for i in list_images[0:int(len(list_images)*(1-test_size))]:
    image = cv2.imread(directory_origin+'/'+str(i))
    if image is not None:
      image = cv2.resize(image,(32,32))
      cv2.imwrite(directory_new_train+str(class_name)+'_'+str(i),image)
    count = count+1
    print(count)
  for j in list_images[int(len(list_images)*(1-test_size)):]:
    image = cv2.imread(directory_origin+'/'+str(j))
    if image is not None:
      image = cv2.resize(image,(32,32))
      cv2.imwrite(directory_new_test+str(class_name)+'_'+str(j),image)
    count = count+1
    print(count)

train_test_split('/content/drive/MyDrive/DL_Assignment_2/PetImages/Cat','/content/drive/MyDrive/DL_Assignment_2/train/','/content/drive/MyDrive/DL_Assignment_2/test/','Cat', test_size=0.3, shuffle_option=True)

train_test_split('/content/drive/MyDrive/DL_Assignment_2/PetImages/Dog','/content/drive/MyDrive/DL_Assignment_2/train/','/content/drive/MyDrive/DL_Assignment_2/test/','Dog', test_size=0.3, shuffle_option=True)

list_train = os.listdir('/content/drive/MyDrive/DL_Assignment_2/train/')
train_df = pd.DataFrame(list_train,columns=['Image_Name'])
train_df

list_test = os.listdir('/content/drive/MyDrive/DL_Assignment_2/test/')
test_df = pd.DataFrame(list_test,columns=['Image_Name'])
test_df

train_label=[]
for i in list_train:
  if i[0]=='C':
    train_label.append(0)
  else:
    train_label.append(1)

test_label=[]
for j in list_test:
  if j[0]=='C':
    test_label.append(0)
  else:
    test_label.append(1)

train_df['Image_Label']=train_label
test_df['Image_Label']=test_label

train_df

test_df

train_df.to_csv('/content/drive/MyDrive/DL_Assignment_2/train/train_meta.csv')
test_df.to_csv('/content/drive/MyDrive/DL_Assignment_2/test/test_meta.csv')

"""## Dataset-Classes and Utility Functions for constructing Data-Loaders"""

class Data_Prepare(Dataset):
  """
  The Class will act as the container for our dataset. It will take your dataframe, the root path, and also the transform function for transforming the dataset.
  """
  def __init__(self, data_frame, root_dir, transform=None):
    self.data_frame = data_frame
    self.root_dir = root_dir
    self.transform = transform
  def __len__(self):
    # Return the length of the dataset
    return len(self.data_frame)
  def __getitem__(self, idx):
    # Return the observation based on an index. Ex. dataset[0] will return the first element from the dataset, in this case the image and the label.
    if torch.is_tensor(idx):
      idx = idx.tolist()    
    img_name = os.path.join(self.root_dir, self.data_frame.iloc[idx, 1])
    image = Image.open(img_name)
    label = self.data_frame.iloc[idx, -1]
    if self.transform:
      image = self.transform(image)
    return (image, label)

def data_preparation(Data_Class, root_directory_train, root_directory_test, train_df, test_df, Mean, Std, Batch_Size = 128, Shuffle = False):
  transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize(Mean, Std)])
  train_dataset = Data_Class(data_frame=train_df,root_dir=root_directory_train,transform = transform)
  train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = Batch_Size, shuffle = Shuffle, num_workers=2, pin_memory=True)
  test_dataset = Data_Class(data_frame=test_df,root_dir=root_directory_test,transform = transform)
  test_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = Batch_Size, shuffle = Shuffle, num_workers=2, pin_memory=True)
  return train_loader, test_loader

train_df = pd.read_csv('/content/drive/MyDrive/DL_Assignment_2/train/train_meta.csv')
test_df = pd.read_csv('/content/drive/MyDrive/DL_Assignment_2/test/test_meta.csv')

train,test = data_preparation(Data_Prepare, '/content/drive/MyDrive/DL_Assignment_2/train', '/content/drive/MyDrive/DL_Assignment_2/test', train_df, test_df, (0,0,0),(1,1,1), Batch_Size = 1024, Shuffle=True )

"""# CNN Architecture Class"""

class CNN_Architecture(torch.nn.Module):
  def __init__(self, output_classes):
    super().__init__()
    self.sequential = torch.nn.Sequential(
        torch.nn.Conv2d(3,6,5),
        torch.nn.MaxPool2d(2,2),
        torch.nn.Conv2d(6,9,5),
        torch.nn.MaxPool2d(2,2))
    self.classify = torch.nn.Sequential(
        torch.nn.Linear(9 * 5 * 5, 32),
        torch.nn.Linear(32, output_classes),
        torch.nn.Sigmoid())
    
  def forward(self, x):
    output = self.sequential(x)
    output = output.view(-1,9*5*5)
    output = self.classify(output)
    return output

"""# Utility Functions to train a Pytorch Model"""

def grad_change(Loss_Function, Optimizer, Label = None, Predicted = None):
  Optimizer.zero_grad()
  loss = Loss_Function(Predicted, Label)
  loss.backward()
  Optimizer.step()
  return loss, Optimizer

def model(Train_Loader, Test_Loader, Epochs, Model_Class=None, Loss_Function=None, Optimizer=None):
  outputs_train=[]
  outputs_test=[]
  for Epoch in range(Epochs):
    running_loss_train=0
    running_loss_test=0
    correct_train=0
    correct_test=0
    for (image, label) in Train_Loader:
      image = image.cuda()
      label = label.cuda()
      out = Model_Class(image)
      loss, Optimizer = grad_change(Loss_Function = Loss_Function, Optimizer = Optimizer, Label = label, Predicted = out)
      running_loss_train += loss.item()
      predicted_train = out.data.max(1, keepdim=True)[1]
      correct_train += predicted_train.eq(label.data.view_as(predicted_train)).sum()
    outputs_train.append((Epoch, running_loss_train/len(Train_Loader.dataset), 100*correct_train/len(Train_Loader.dataset)))
    with torch.no_grad():
      for (image, label) in Test_Loader:
        image = image.cuda()
        label = label.cuda()
        out = Model_Class(image)
        loss = Loss_Function(out,label)
        running_loss_test += loss.item()
        predicted_test = out.data.max(1, keepdim=True)[1]
        correct_test += predicted_test.eq(label.data.view_as(predicted_test)).sum()
      outputs_test.append((Epoch, running_loss_test/len(Test_Loader.dataset), 100*correct_test/len(Test_Loader.dataset)))
  return Model_Class, outputs_train, outputs_test

def Model_Initializer():
  return CNN_Architecture(output_classes=2).cuda()

"""# Variant for Vanilla SGD"""

train_vanilla,test_vanilla = data_preparation(Data_Prepare, '/content/drive/MyDrive/DL_Assignment_2/train', '/content/drive/MyDrive/DL_Assignment_2/test', train_df, test_df, (0,0,0),(1,1,1), Batch_Size = 1, Shuffle=True )
model_vanilla= Model_Initializer()
loss_function_vanilla = torch.nn.CrossEntropyLoss().cuda()
optimizer_vanilla = torch.optim.SGD(model_vanilla.parameters(),lr=0.01)
model_vanilla,output_train_vanilla,output_test_vanilla = model(train_vanilla,test_vanilla,15,model_vanilla,loss_function_vanilla,optimizer_vanilla)

"""# Variations in Mini_Batch Optimizers"""

model_2= Model_Initializer()
model_3= Model_Initializer()
model_4= Model_Initializer()
loss_function = torch.nn.CrossEntropyLoss().cuda()

optimizer_2 = torch.optim.SGD(model_2.parameters(),lr=0.01)
optimizer_3 = torch.optim.SGD(model_3.parameters(),lr=0.01,momentum=0.5)
optimizer_4 = torch.optim.Adam(model_4.parameters())

model_2,output_train_2,output_test_2 = model(train,test,15,model_2,loss_function,optimizer_2)
model_3,output_train_3,output_test_3 = model(train,test,15,model_3,loss_function,optimizer_3)
model_4,output_train_4,output_test_4 = model(train,test,15,model_4,loss_function,optimizer_4)

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,16)],[output_train_vanilla[i][1] for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_train_2[i][1] for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_train_3[i][1] for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_train_4[i][1] for i in range(0,15)])
plt.xlabel("Epochs")
plt.ylabel("Average Loss")
plt.title("Loss v/s Epochs for Training with variations in optimizers")
plt.legend(["Vanilla SGD","Mini-Batch with SGD","Mini-Batch with Momentum","Mini-Batch with Adam"])
plt.show()

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,16)],[output_test_vanilla[i][1] for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_test_2[i][1] for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_test_3[i][1] for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_test_4[i][1] for i in range(0,15)])
plt.xlabel("Epochs")
plt.ylabel("Average Loss")
plt.title("Loss v/s Epochs for Testing with variations in optimizers")
plt.legend(["Vanilla SGD","Mini-Batch with SGD","Mini-Batch with Momentum","Mini-Batch with Adam"])
plt.show()

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,16)],[output_train_vanilla[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_train_2[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_train_3[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_train_4[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.xlabel("Epochs")
plt.ylabel("Accuracy %")
plt.title("Accuracy v/s Epochs for Training with variations in optimizers")
plt.legend(["Vanilla SGD","Mini-Batch with SGD","Mini-Batch with Momentum","Mini-Batch with Adam"])
plt.show()

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,16)],[output_test_vanilla[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_test_2[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_test_3[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_test_4[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.xlabel("Epochs")
plt.ylabel("Accuracy %")
plt.title("Accuracy v/s Epochs for Testing with variations in optimizers")
plt.legend(["Vanilla SGD","Mini-Batch with SGD","Mini-Batch with Momentum","Mini-Batch with Adam"])
plt.show()

"""# Variations in Batches and Shuffling"""

train_1,test_1 = data_preparation(Data_Prepare, '/content/drive/MyDrive/DL_Assignment_2/train', '/content/drive/MyDrive/DL_Assignment_2/test', train_df, test_df, (0,0,0),(1,1,1), Batch_Size = 1024, Shuffle=False )
train_2,test_2 = data_preparation(Data_Prepare, '/content/drive/MyDrive/DL_Assignment_2/train', '/content/drive/MyDrive/DL_Assignment_2/test', train_df, test_df, (0,0,0),(1,1,1), Batch_Size = 2048, Shuffle=True )
train_3,test_3 = data_preparation(Data_Prepare, '/content/drive/MyDrive/DL_Assignment_2/train', '/content/drive/MyDrive/DL_Assignment_2/test', train_df, test_df, (0,0,0),(1,1,1), Batch_Size = 512, Shuffle=True )

model_batch_1= Model_Initializer()
model_batch_2= Model_Initializer()
model_batch_3= Model_Initializer()

optimizer_batch_1 = torch.optim.Adam(model_batch_1.parameters())
optimizer_batch_2 = torch.optim.Adam(model_batch_2.parameters())
optimizer_batch_3 = torch.optim.Adam(model_batch_3.parameters())

model_batch_1,output_train_batch_1,output_test_batch_1 = model(train_1,test_1,15,model_batch_1,loss_function,optimizer_batch_1)
model_batch_2,output_train_batch_2,output_test_batch_2 = model(train_2,test_2,15,model_batch_2,loss_function,optimizer_batch_2)
model_batch_3,output_train_batch_3,output_test_batch_3 = model(train_3,test_3,15,model_batch_3,loss_function,optimizer_batch_3)

"""## Variations in Mini-Batches"""

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,16)],[output_train_2[i][1] for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_train_batch_2[i][1] for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_train_batch_3[i][1] for i in range(0,15)])
plt.xlabel("Epochs")
plt.ylabel("Average Loss")
plt.title("Loss v/s Epochs for Training with variations in Mini-Batches")
plt.legend(["1024","2048","512"])
plt.show()

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,16)],[output_test_2[i][1] for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_test_batch_2[i][1] for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_test_batch_3[i][1] for i in range(0,15)])
plt.xlabel("Epochs")
plt.ylabel("Average Loss")
plt.title("Loss v/s Epochs for Testing with variations in Mini-Batches")
plt.legend(["1024","2048","512"])
plt.show()

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,16)],[output_train_2[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_train_batch_2[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_train_batch_3[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.xlabel("Epochs")
plt.ylabel("Accuracy %")
plt.title("Accuracy v/s Epochs for Training with variations in Mini-Batches")
plt.legend(["1024","2048","512"])
plt.show()

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,16)],[output_test_2[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_test_batch_2[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_test_batch_3[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.xlabel("Epochs")
plt.ylabel("Accuracy %")
plt.title("Accuracy v/s Epochs for Testing with variations in Mini-Batches")
plt.legend(["1024","2048","512"])
plt.show()

"""## Variations in Shuffling"""

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,16)],[output_train_4[i][1] for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_train_batch_1[i][1] for i in range(0,15)])
plt.xlabel("Epochs")
plt.ylabel("Average Loss")
plt.title("Loss v/s Epochs for Training with variations in shuffling")
plt.legend(["True","False"])
plt.show()

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,16)],[output_test_4[i][1] for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_test_batch_1[i][1] for i in range(0,15)])
plt.xlabel("Epochs")
plt.ylabel("Average Loss")
plt.title("Loss v/s Epochs for Testing with variations in shuffling")
plt.legend(["True","False"])
plt.show()

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,16)],[output_train_4[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_train_batch_1[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.xlabel("Epochs")
plt.ylabel("Accuracy %")
plt.title("Accuracy v/s Epochs for Training with variations in shuffling")
plt.legend(["True","False"])
plt.show()

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,16)],[output_test_4[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_test_batch_1[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.xlabel("Epochs")
plt.ylabel("Accuracy %")
plt.title("Accuracy v/s Epochs for Testing with variations in shuffling")
plt.legend(["True","False"])
plt.show()

"""# Variations in Values of Beta-1"""

model_beta_1_1= Model_Initializer()
model_beta_1_2= Model_Initializer()

optimizer_beta_1_1 = torch.optim.Adam(model_beta_1_1.parameters(), betas=(0.8,0.999))
optimizer_beta_1_2 = torch.optim.Adam(model_beta_1_2.parameters(), betas=(0.7,0.999))

model_beta_1_1,output_train_beta_1_1,output_test_beta_1_1 = model(train,test,15,model_beta_1_1,loss_function,optimizer_beta_1_1)
model_beta_1_2,output_train_beta_1_2,output_test_beta_1_2 = model(train,test,15,model_beta_1_2,loss_function,optimizer_beta_1_2)

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,16)],[output_train_4[i][1] for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_train_beta_1_1[i][1] for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_train_beta_1_2[i][1] for i in range(0,15)])
plt.xlabel("Epochs")
plt.ylabel("Average Loss")
plt.title("Loss v/s Epochs for Training with variations in Beta-1")
plt.legend(["0.9","0.8","0.7"])
plt.show()

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,16)],[output_test_4[i][1] for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_test_beta_1_1[i][1] for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_test_beta_1_2[i][1] for i in range(0,15)])
plt.xlabel("Epochs")
plt.ylabel("Average Loss")
plt.title("Loss v/s Epochs for Testing with variations in Beta-1")
plt.legend(["0.9","0.8","0.7"])
plt.show()

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,16)],[output_train_4[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_train_beta_1_1[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_train_beta_1_2[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.xlabel("Epochs")
plt.ylabel("Accuracy %")
plt.title("Accuracy v/s Epochs for Training with variations in Beta-1")
plt.legend(["0.9","0.8","0.7"])
plt.show()

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,16)],[output_test_4[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_test_beta_1_1[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_test_beta_1_2[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.xlabel("Epochs")
plt.ylabel("Accuracy %")
plt.title("Accuracy v/s Epochs for Testing with variations in Beta-1")
plt.legend(["0.9","0.8","0.7"])
plt.show()

"""# Variations in Values of Beta-2"""

model_beta_2_1= Model_Initializer()
model_beta_2_2= Model_Initializer()

optimizer_beta_2_1 = torch.optim.Adam(model_beta_2_1.parameters(), betas=(0.9,0.899))
optimizer_beta_2_2 = torch.optim.Adam(model_beta_2_2.parameters(), betas=(0.9,0.949))

model_beta_2_1,output_train_beta_2_1,output_test_beta_2_1 = model(train,test,15,model_beta_2_1,loss_function,optimizer_beta_2_1)
model_beta_2_2,output_train_beta_2_2,output_test_beta_2_2 = model(train,test,15,model_beta_2_2,loss_function,optimizer_beta_2_2)

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,16)],[output_train_4[i][1] for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_train_beta_2_1[i][1] for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_train_beta_2_2[i][1] for i in range(0,15)])
plt.xlabel("Epochs")
plt.ylabel("Average Loss")
plt.title("Loss v/s Epochs for Training with variations in Beta-2")
plt.legend(["0.999","0.899","0.949"])
plt.show()

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,16)],[output_test_4[i][1] for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_test_beta_2_1[i][1] for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_test_beta_2_2[i][1] for i in range(0,15)])
plt.xlabel("Epochs")
plt.ylabel("Average Loss")
plt.title("Loss v/s Epochs for Testing with variations in Beta-2")
plt.legend(["0.999","0.899","0.949"])
plt.show()

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,16)],[output_train_4[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_train_beta_2_1[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_train_beta_2_2[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.xlabel("Epochs")
plt.ylabel("Accuracy %")
plt.title("Accuracy v/s Epochs for Training with variations in Beta-2")
plt.legend(["0.999","0.899","0.949"])
plt.show()

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,16)],[output_test_4[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_test_beta_2_1[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.plot([j for j in range(1,16)],[output_test_beta_2_2[i][2].cpu().detach().numpy() for i in range(0,15)])
plt.xlabel("Epochs")
plt.ylabel("Accuracy %")
plt.title("Accuracy v/s Epochs for Testing with variations in Beta-2")
plt.legend(["0.999","0.899","0.949"])
plt.show()